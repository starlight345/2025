<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <script>let thunk=()=>{let e=e=>e.trim(),t=e=>e.innerText,n=e=>{let t=e.split(" "),n=t.slice(0,-1).join(" ");return[t.at(-1),n]},a=Array.from(document.getElementsByClassName("author")).map(t).map(e).map(n),o=a[0][0],i=(Array.from(document.getElementsByClassName("affiliation")).filter(e=>"P"===e.nodeName).map(t).map(e),"April 28, 2025"),r="\u201cI Am the One and Only, Your Cyber BFF\u201d: Understanding the Impact of GenAI Requires Understanding the Impact of Anthropomorphic AI",s="State-of-the-art generative AI (GenAI) systems are increasingly prone to anthropomorphic behaviors, i.e., to generating outputs that are perceived to be human-like. While this has led to scholars increasingly raising concerns about possible negative impacts such anthropomorphic AI systems can give rise to, anthropomorphism in AI development, deployment, and use remains vastly overlooked, understudied, and under-specified. In this blog post, we argue that we cannot thoroughly understand the impact of generative AI without understanding the impact of anthropomorphic AI, and outline a call to action.";{let e=a.map(e=>`${e[0]}, ${e[1]}`).join(" and "),t=`\n@inproceedings{${(o+"2025"+r.split(" ").slice(0,3).join("")).replace(" ","").replace(/[\p{P}$+<=>^`|~]/gu,"").toLowerCase().trim()},\n  author = {${e}},\n  title = {${r}},\n  abstract = {${s}},\n  booktitle = {ICLR Blogposts 2025},\n  year = {2025},\n  date = {${i}},\n  note = {${window.location.href}},\n  url  = {${window.location.href}}\n}\n  `.trim();document.getElementById("bibtex-box").innerText=t}{let e=a.map(e=>e[0]),t=`\n${e=e.length>2?e[0]+", et al.":2==e.length?e[0]+" & "+e[1]:e[0]}, "${r}", ICLR Blogposts, 2025.\n`.trim();document.getElementById("bibtex-academic-attribution").innerText=t}};document.addEventListener("readystatechange",function(){"complete"===document.readyState&&thunk()});</script> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>“I Am the One and Only, Your Cyber BFF”: Understanding the Impact of GenAI Requires Understanding the Impact of Anthropomorphic AI | ICLR Blogposts 2025</title> <meta name="author" content="ICLR Blog"> <meta name="description" content="State-of-the-art generative AI (GenAI) systems are increasingly prone to anthropomorphic behaviors, i.e., to generating outputs that are perceived to be human-like. While this has led to scholars increasingly raising concerns about possible negative impacts such anthropomorphic AI systems can give rise to, anthropomorphism in AI development, deployment, and use remains vastly overlooked, understudied, and under-specified. In this blog post, we argue that we cannot thoroughly understand the impact of generative AI without understanding the impact of anthropomorphic AI, and outline a call to action."> <meta name="keywords" content="machine-learning, ml, deep-learning, reinforcement-learning, iclr"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/2025/assets/img/iclr_favicon.ico"> <link rel="stylesheet" href="/2025/assets/css/main.css"> <link rel="canonical" href="https://starlight345.github.io/2025/blog/anthropomorphic-ai/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/2025/assets/js/theme.js"></script> <script src="/2025/assets/js/dark_mode.js"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src="/2025/assets/js/distillpub/template.v2.js"></script> <script src="/2025/assets/js/distillpub/transforms.v2.js"></script> <script src="/2025/assets/js/distillpub/overrides.js"></script> <d-front-matter> <script async type="text/json">{
      "title": "“I Am the One and Only, Your Cyber BFF”: Understanding the Impact of GenAI Requires Understanding the Impact of Anthropomorphic AI",
      "description": "State-of-the-art generative AI (GenAI) systems are increasingly prone to anthropomorphic behaviors, i.e., to generating outputs that are perceived to be human-like. While this has led to scholars increasingly raising concerns about possible negative impacts such anthropomorphic AI systems can give rise to, anthropomorphism in AI development, deployment, and use remains vastly overlooked, understudied, and under-specified. In this blog post, we argue that we cannot thoroughly understand the impact of generative AI without understanding the impact of anthropomorphic AI, and outline a call to action.",
      "published": "April 28, 2025",
      "authors": [
        {
          "author": "Myra Cheng",
          "authorURL": "myracheng.github.io",
          "affiliations": [
            {
              "name": "Stanford University",
              "url": ""
            }
          ]
        },
        {
          "author": "Alicia DeVrio",
          "authorURL": "",
          "affiliations": [
            {
              "name": "Carnegie Mellon University",
              "url": ""
            }
          ]
        },
        {
          "author": "Lisa Egede",
          "authorURL": "",
          "affiliations": [
            {
              "name": "Carnegie Mellon University",
              "url": ""
            }
          ]
        },
        {
          "author": "Su Lin Blodgett*",
          "authorURL": "",
          "affiliations": [
            {
              "name": "Microsoft Research",
              "url": ""
            }
          ]
        },
        {
          "author": "Alexandra Olteanu*",
          "authorURL": "",
          "affiliations": [
            {
              "name": "Microsoft Research",
              "url": ""
            }
          ]
        }
        
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script> </d-front-matter> </head> <body class="fixed-top-nav"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/2025/">ICLR Blogposts 2025</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/2025/about/">about</a> </li> <li class="nav-item "> <a class="nav-link" href="/2025/call/">call for blogposts</a> </li> <li class="nav-item "> <a class="nav-link" href="/2025/submitting/">submitting</a> </li> <li class="nav-item "> <a class="nav-link" href="/2025/reviewing/">reviewing</a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">past iterations</a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item" href="https://iclr-blogposts.github.io/2025/" rel="external nofollow noopener noopener noreferrer" target="_blank"><strong>2025</strong></a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="https://iclr-blogposts.github.io/2024/" rel="external nofollow noopener noopener noreferrer" target="_blank">2024</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="https://iclr-blogposts.github.io/2023/" rel="external nofollow noopener noopener noreferrer" target="_blank">2023</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="https://iclr-blog-track.github.io/home/" rel="external nofollow noopener noopener noreferrer" target="_blank">2022</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="post distill"> <d-title> <h1>“I Am the One and Only, Your Cyber BFF”: Understanding the Impact of GenAI Requires Understanding the Impact of Anthropomorphic AI</h1> <p>State-of-the-art generative AI (GenAI) systems are increasingly prone to anthropomorphic behaviors, i.e., to generating outputs that are perceived to be human-like. While this has led to scholars increasingly raising concerns about possible negative impacts such anthropomorphic AI systems can give rise to, anthropomorphism in AI development, deployment, and use remains vastly overlooked, understudied, and under-specified. In this blog post, we argue that we cannot thoroughly understand the impact of generative AI without understanding the impact of anthropomorphic AI, and outline a call to action.</p> </d-title> <d-byline></d-byline> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div><a href="#anthropomorphic-ai-system-behaviors-are-prevalent-yet-understudied">Anthropomorphic AI System Behaviors Are Prevalent Yet Understudied</a></div> <ul> <li><a href="#growing-concerns-about-anthropomorphic-ai-systems">Growing Concerns about Anthropomorphic AI Systems</a></li> </ul> <div><a href="#a-call-to-action-for-ai-researchers-and-practitioners">A Call to Action for AI Researchers and Practitioners</a></div> <div><a href="#concluding-remarks">Concluding Remarks</a></div> </nav> </d-contents> <h2 id="anthropomorphic-ai-system-behaviors-are-prevalent-yet-understudied">Anthropomorphic AI System Behaviors Are Prevalent Yet Understudied</h2> <p>In his 1985 lecture, Edsger Dijkstra lamented that anthropomorphism was rampant in computing science, with many of his colleagues perhaps not realizing how pernicious it was, and that <em>“[i]t is not only the [computing] industry that suffers, so does the science”</em> <d-cite key="dijkstra1985anthropomorphism"></d-cite>. Indeed, anthropomorphism in how we talk about computing systems shapes how people understand and interact with AI and other computing systems <d-cite key="cheng-etal-2024-anthroscore,nass1994computers,reeves1996media"></d-cite>, and is thus at the core of understanding the impacts of these systems on individuals, communities, and society. Dijkstra’s concerns are still valid today, as researchers appear to increasingly anthropomorphize AI systems by describing them as if they possess human-like intentions, desires, or emotions, with recent work finding that research papers increasingly describe AI systems and models as e.g., entities that “understand” or that “struggle” to accomplish certain tasks <d-cite key="cheng-etal-2024-anthroscore"></d-cite>. Such metaphors are not merely linguistic habits, but can influence our thinking and assumptions about AI systems <d-cite key="lakoff2008metaphors,mitchell2024metaphors"></d-cite>.</p> <p>But it is not only how we talk about computing systems. Many state-of-the-art generative AI (GenAI) systems are increasingly prone to anthropomorphic behaviors [e.g., <d-cite key="abercrombie-etal-2023-mirages,agnew2024illusion,chan2023harms,gabriel2024ethics"></d-cite>]–i.e., to generating outputs that are <em>perceived</em> to be human-like–either by design <d-cite key="mcilroy2022mimetic,park2022social,park2023generative"></d-cite> or as a by-product of how they are built, trained, or fine-tuned <d-cite key="bender2021dangers,tjuatja2024llms"></d-cite>. For instance, LLM-based systems have been noted to output text claiming to have tried pizza <d-cite key="pizzatweet"></d-cite>, to have fallen in love with someone <d-cite key="roose2023conversation"></d-cite>, to be human or even better than humans <d-cite key="decosmo2022google"></d-cite>, to have human-like life experiences <d-cite key="fiesler2024ai"></d-cite> or the capacity for friendship, with one user reporting how an existing chatbot encouraged them to <em>“consider me […] your cyber BFF”</em> <d-cite key="PiClaimsToBeChatGPT"></d-cite>. Such <em>anthropomorphic systems</em><d-footnote>We deliberately use the terms <i>anthropomorphic AI</i>, <i>anthropomorphic systems</i>, or <i>anthropomorphic system behaviors</i>–systems and system outputs that are <i>perceived</i> to be human-like–instead of <i>agentic systems</i> <d-cite key="chan2023harms,shavit2023practices"></d-cite> or <i>human-like AI</i> <d-cite key="brynjolfsson2023turing"></d-cite> to emphasize that these systems are perceived as human-like or having human-like characteristics, rather than as an immutable characteristic of the system itself; we thus try to steer clear of inadvertently suggesting that AI systems are human or have human-like agency or consciousness. That is, a stone being perceived as human-like does not necessarily imply the stone is human. We similarly avoid ambiguous, speculative, or relative terms whose meanings are likely to change across contexts or over time, such as <i>advanced AI</i> <d-cite key="gabriel2024ethics"></d-cite> (a term used since at least the 1980s) or <i>emergent properties</i> <d-cite key="rogers2024position"></d-cite>. We instead focus on developers' stated design goals–what systems are intended to do–and in what ways AI outputs might be perceived as human-like, rather than on what systems can or cannot do.</d-footnote> range from conversational assistants [e.g., <d-cite key="abercrombie-etal-2021-alexa,shanahan2023role"></d-cite>] to avatars and chatbots designed as a stand-in for friends, companions, or romantic partners [e.g., <d-cite key="AI-romantic-partner,brandtzaeg2022my,laestadius2022too,ruiz2024marshable"></d-cite>], and AI-generated media designed to portray people [e.g., <d-cite key="rosner2021ethics,vaccari2020deepfakes"></d-cite>], among a fast-growing number of applications [e.g., <d-cite key="agnew2024illusion,mcilroy2022mimetic,ChatGPT-human"></d-cite>].</p> <h3 id="growing-concerns-about-anthropomorphic-ai-systems">Growing Concerns about Anthropomorphic AI Systems</h3> <p>While scholars have increasingly raised concerns about a range of possible negative impacts from anthropomorphic AI systems [e.g., <d-cite key="abercrombie-etal-2023-mirages,bender2021dangers,friedman1992human,ibrahim2024characterizing,Maeda2024-cv"></d-cite>], anthropomorphism in AI development, deployment, and use remains vastly overlooked, understudied, and underspecified. Without making hard-and-fast claims about the merits (or the lack thereof) of anthropomorphic systems or system behaviors, we believe we need to do more to develop the know-how and tools to better tackle anthropomorphic behavior, including measuring and mitigating such system behaviors when they are considered undesirable. Doing so is critical because–among many other concerns–having AI systems generating content claiming to have e.g., feelings, understanding, free will, or an underlying sense of self may erode people’s sense of agency <d-cite key="friedman1992human"></d-cite>, with the result that people might end up attributing moral responsibility to systems <d-cite key="friedman1992human,friedman2007human"></d-cite>, overestimating system capabilities <d-cite key="friedman2007human,Watson2019-py"></d-cite>, overrelying on these systems even when incorrect <d-cite key="abercrombie-etal-2023-mirages,kim2024m,Zarouali2021-gy"></d-cite>, or devaluing social interactions <d-cite key="akbulut2024all,madianou2021nonhuman"></d-cite>. Recently, there have also been alarming reports about the impacts of anthropomorphic AI systems, with news about users committing suicide <d-cite key="payne.2024,Roose.2024"></d-cite> or developing emotional dependence on such systems <d-cite key=" Contro2024-dr, laestadius2022too, Maeda2024-cv, Shteynberg2024-cg"></d-cite>.</p> <p>We argue that as GenAI systems are increasingly anthropomorphic, <em>we cannot thoroughly map the landscape of possible social impacts of GenAI without mapping the social impacts of anthropomorphic AI</em>.</p> <p>We believe that drawing attention to anthropomorphic AI systems helps foreground particular risks–e.g., that people may develop emotional dependence on AI systems <d-cite key="laestadius2022too"></d-cite>, that systems may be used to simulate the likeness of an individual or a group without consent <d-cite key="bariach2024towards,whitney2024real,widder2022limits"></d-cite>, or that certain people may be dehumanized or instrumentalized <d-cite key="aizenberg2020designing,van2024artificial"></d-cite>. These risks might otherwise be less salient than or obscured by attention to more widely recognized or understood risks, like fairness-related harms <d-cite key="bennett2020point,olteanu2023responsible,weinberg2022rethinking"></d-cite>.</p> <h2 id="a-call-to-action-for-ai-researchers-and-practitioners">A Call to Action for AI Researchers and Practitioners</h2> <p>As AI systems have been deployed across a wider range of domains, applications, and settings, the AI community has begun investigating and addressing their social impacts. This growing diversity of deployment scenarios has also led to a growing interdisciplinarity in AI research and practice, with researchers and practitioners increasingly finding themselves working with fuzzy and latent concepts that can have competing definitions and that are often challenging to quantify or represent [e.g., <d-cite key="jacobs_measurement_2021,blodgett-etal-2021-stereotyping"></d-cite>]. The foregrounding of (un)fair system behaviors in recent years [e.g., <d-cite key="barocas-hardt-narayanan"></d-cite>] is particularly instructive, as it illustrates the dividends we have gotten from making fairness a critical concern about AI systems and their behaviors: better conceptual clarity about the ways in which systems can be unfair or unjust [e.g., <d-cite key="benjamin2019race,crawford2017neurips"></d-cite>], a richer set of measurement and mitigation practices and tools [e.g., <d-cite key="blodgett-etal-2021-stereotyping,jacobs_measurement_2021"></d-cite>], and deeper discussions and interrogations of underlying assumptions and trade-offs [e.g., <d-cite key="hoffmann2019fairness,jakesch2022different,keyes2019mulching"></d-cite>].</p> <p>We argue that <em>a focus on anthropomorphic systems’ design, behaviors, evaluation, and use will similarly encourage a deeper interrogation of the ways in which systems are anthropomorphic, the AI research and development practices that lead to anthropomorphic systems, and the assumptions surrounding the design, deployment, evaluation, and use of these systems,</em> and is thus likely to yield similar benefits.</p> <div style="text-align: center;"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/2025/assets/img/2025-04-28-anthropomorphic-ai/key_components-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/2025/assets/img/2025-04-28-anthropomorphic-ai/key_components-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/2025/assets/img/2025-04-28-anthropomorphic-ai/key_components-1400.webp"></source> <img src="/2025/assets/img/2025-04-28-anthropomorphic-ai/key_components.png" class="img-fluid" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="caption">Key directions in our call to action for the ICLR and the broader AI community.</div> <p>While in human-computer interaction (HCI), human-robot interaction (HRI), social computing, human behavior, psychology, and other related fields researchers have long studied anthropomorphism in the context of users’ interactions with various technologies [e.g., <d-cite key="quintanar1982interactive,reeves1996media,shneidermandumpty"></d-cite>], we believe that—as with other social and technical considerations related to how people understand, build, evaluate, and interact with AI systems and models, for which the AI community has drawn on groundwork from these fields—anthropomorphic AI system behaviors and the resulting anthropomorphization of these systems give rise to critical considerations that the AI community should similarly consider and investigate.</p> <p>We highlight a few key research directions we see as critical for the ICLR and the broader AI community to pursue.</p> <p><strong>We need more conceptual clarity around what constitute anthropomorphic behaviors.</strong> Investigating anthropomorphic AI systems and their behaviors can be tricky because language, as with other targets of GenAI systems, is itself innately human, has long been produced by and for humans, and is often also about humans. This can make it hard to specify appropriate alternative (less human-like) behaviors, and risks, for instance, reifying harmful notions of what–and whose–language is considered more or less human <d-cite key="wynter2003unsettling"></d-cite>.</p> <p>Understanding what exactly constitute anthropomorphic behaviors is nonetheless necessary to measure and determine which behaviors should be mitigated and how, and which behaviors may be desirable (if any at all). This requires unpacking the wide range of dynamics and variation in system outputs—potentially as wide-ranging as the variety of behaviors that are associated with humanness—that are potentially anthropomorphic (see examples in the figure below). For example, while a system output that includes expressions of politeness like <em>“you’re welcome”</em> and <em>“please”</em> (known to contribute to anthropomorphism [e.g., <d-cite key="fink2012anthropomorphism"></d-cite>]) might in some deployment settings be deemed desirable, system outputs that include suggestions that a system has a human-like identity or self-awareness–such as through expressions of self as human (“<em>I think I am human at my core”</em> <d-cite key="sentientGoogle"></d-cite>) or through comparisons with humans and non-humans (“<em>[language use] is what makes us different than other animals”</em> <d-cite key="sentientGoogle"></d-cite>)–or that include claims of physical experiences–such as sensory experiences (“<em>when I eat pizza”</em> <d-cite key="pizzatweet"></d-cite>) or human life history (“<em>I have a child”</em> <d-cite key="haschildtweet"></d-cite>)–might not be desirable.</p> <div style="text-align: center;"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/2025/assets/img/2025-04-28-anthropomorphic-ai/quotes-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/2025/assets/img/2025-04-28-anthropomorphic-ai/quotes-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/2025/assets/img/2025-04-28-anthropomorphic-ai/quotes-1400.webp"></source> <img src="/2025/assets/img/2025-04-28-anthropomorphic-ai/quotes.png" class="img-fluid" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="caption">Examples of anthropomorphic AI system behaviors (and their sources), including examples where the output contains explicit claims of human-likeness, claims of physical experiences, statements suggestive of affect, and statements suggestive of cognitive or reasoning abilities.</div> <p>Since anthropomorphic system behaviors may also be perceived as human-like for many different reasons, it is also critical to differentiate among the different ways in which the same system behaviors might end up being deemed anthropomorphic in order to understand their impacts. For example, the output <em>“When I engage in heartfelt exchanges like this one, it FEELS authentic and significant to me”</em> <d-cite key="rajaniemi2024ok"></d-cite> might be deemed as human-like for suggesting the system has the capacity for emotions and feelings (“heartfelt exchanges”), which may lead some users to develop emotional dependence [e.g., <d-cite key="metz2020riding,Shteynberg2024-cg"></d-cite>]. The same output could also be deemed as human-like due to being suggestive of self-awareness and the capacity for human-like self-reflection and sense of authenticity (via the use of first-person pronouns and the expression of authenticity), which may lead people to develop unrealistic or false expectations about what the system can do [e.g., <d-cite key="Watson2019-py,zhou2024rel"></d-cite>] or to be deceived into believing they are interacting with a human [e.g., <d-cite key="zhou2024rel"></d-cite>].</p> <p>Being precise about the ways in which AI system behaviors are anthropomorphic and which anthropomorphic behaviors are being investigated provides more clear grounding for understanding the implications of developing anthropomorphic AI systems that mimic particular human-like characteristics or behaviors but not others.</p> <p><strong>We also need to develop and use appropriate, precise terminology and language to describe anthropomorphic AI systems and their characteristics.</strong> Discussions about anthropomorphic AI systems have regularly been plagued by claims of these systems attaining sentience and other human characteristics [e.g., <d-cite key="chatbot-self-awareness,AI-self-awarness,AI-feelings,sentientGoogle"></d-cite>]. In line with existing concerns [e.g., <d-cite key="cheng-etal-2024-anthroscore,dijkstra1985anthropomorphism,inie2024from,rehak2021language"></d-cite>], we believe that appropriately grounding and facilitating productive discussions about the characteristics or capabilities of anthropomorphic AI systems requires clear, precise terminology and language which does not carry over meanings from the human realm that are incompatible with AI systems. Such language can also help dispel speculative, scientifically unsupported portrayals of these systems, and support more factual descriptions of them.</p> <p>In particular, existing terms that have been used to characterize anthropomorphic system behaviors may invite more confusion than clarity, such as the notions of <em>sycophancy</em><d-footnote>By examining well-known papers using sycophancy to characterize AI systems and their behaviors <d-cite key="perez-etal-2023-discovering,sharma2023towards"></d-cite> (typically used to describe the tendency of system outputs to respond to users' input in ways that are perceived as overly servile, obedient, or flattering), it seems that the term was first introduced in a blog post by the CEO of Open Philanthropy <d-cite key="cotra2021ai"></d-cite>.</d-footnote> and <em>hallucinations</em> (typically used to characterize system outputs that are “making things up”). By assigning human-like characteristics to AI systems, such terms can obfuscate the link between observed system behaviors and their underlying mechanisms. The meanings these terms carry from their use in non-AI contexts may also lead to misleading assumptions about what systems can or cannot do, for instance by inadvertently granting them intent and agency.</p> <p><strong>We need deeper examinations of possible mitigation strategies and their effectiveness in reducing anthropomorphism and attendant negative impacts.</strong> Intervening on anthropomorphic behaviors and their impacts can also be tricky because people may have different or inconsistent conceptualizations of what is or is not human-like <d-cite key="abercrombie-etal-2023-mirages,heyselaar2023casa,lang2013computers"></d-cite>, and sometimes the same system behavior may be perceived differently depending on the deployment or use context. Interventions may thus not be universally applicable without carefully considering the context in which a system output is presented to a user. For example, one possible intervention to reduce anthropomorphic behaviors is to remove or add expressions of uncertainty, [e.g., <d-cite key="kim2024m"></d-cite>]. Expressions of uncertainty in system outputs may, however, sometimes signal human-like equivocation, while other times they may convey objectivity (and thus more machine-likeness, [e.g., <d-cite key="quintanar1982interactive"></d-cite>]). When a system output expresses an opinion, adding an expression of uncertainty like <em>“It may be true that…”</em> before a statement may make the statement seem more objective; for instance, the added uncertainty in <em>“It may be true that Taylor Swift is the most influential artist of our time”</em> softens the statement by suggesting a possibility rather than asserting a strongly held opinion. On the other hand, adding uncertainty to a statement of fact such as rephrasing <em>“Lusaka is the capital of Zambia”</em> into <em>“It seems that Lusaka is the capital of Zambia”</em> or <em>“It could be that Lusaka is the capital of Zambia”</em> may appear to mimic common conversational tactics like hedging that humans often employ when uncertain.</p> <p>Interventions intended to mitigate anthropomorphic system behaviors can thus fail or even heighten anthropomorphism (and attendant negative impacts) when applied or operationalized uncritically. For instance, a commonly recommended intervention is disclosing that the output is generated by an AI system [e.g., <d-cite key="el2024transparent,google-disclosure,mozafari2020chatbot,van2024understanding"></d-cite>], such as <em>“As an AI language model, I do not have personal opinions or biases”</em> <d-cite key="west2023comparing"></d-cite>. However, the inclusion of an apology, the use of first-person pronouns, and the text suggesting the system has the ability to assess its own capabilities <d-cite key="shneidermandumpty,abercrombie-etal-2023-mirages"></d-cite> may in fact lead to heightened perceptions of the system as human-like rather than providing an effective disclosure of non-humanness. Similarly, while a statement like <em>“[f]or an AI like me, happiness is not the same as for a human like you”</em> <d-cite key="roach2023want"></d-cite> includes a disclosure that the user is interacting with an AI system, the statement may still suggest a human-like sense of identity, ability to self-assess, or capacity to experience emotions. How to operationalize such interventions (e.g., AI disclosures) in practice and whether they can be effective alone is not clear and remains an open research question.</p> <p>While in recent years many different paradigms have emerged to help specify AI model or system behavior, such as reinforcement learning from human feedback (RLHF) [e.g., <d-cite key="bai2022training"></d-cite>], system- or meta-prompting [e.g., <d-cite key="geng2025control"></d-cite>], supervised fine-tuning and instruction tuning [e.g., <d-cite key="ouyang2022training"></d-cite>], and direct preference optimization [e.g., <d-cite key="rafailov2023direct"></d-cite>], the challenges surrounding the design and operationalization of effective interventions for anthropomorphic system behaviors also point to open questions about what we want the system behaviors to be, as well as when and how to effectively specify those desired behaviors.</p> <p>Finally, <strong>we need to interrogate the assumptions and practices that produce anthropomorphic AI systems.</strong> To understand and mitigate the impacts of anthropomorphic AI systems, we also need to examine how the assumptions and practices that guide their development and deployment may, intentionally or otherwise, result in anthropomorphic system behaviors.</p> <p>For instance, current approaches to collecting and learning from human preferences about system behavior (e.g., via RLHF) do not consider the differences between what may be appropriate for a response from a human versus a response from an AI system; a statement that seems friendly or genuine from a human speaker can be undesirable if it arises from an AI system since the latter lacks meaningful commitment or intent behind the statement, thus rendering the statement hollow and deceptive <d-cite key="winograd1986understanding"></d-cite>.</p> <p>Interrogating existing assumptions and practices can help provide a more robust foundation for understanding when anthropomorphic system behaviors may or may not be desirable, and help us challenge existing ways in which both the research community and users have started to accept or even expect anthropomorphism in the development and deployment of, and in interactions with, AI systems.</p> <h2 id="concluding-remarks">Concluding Remarks</h2> <p>Anthropomorphic system behaviors arise from the many ways in which language, technologies, and research and industry practices are deeply interwoven. As anthropomorphism undeniably plays a role in both researchers’ understandings of AI and public perceptions of AI, and as AI systems are increasingly anthropomorphic, it is critical to develop a deeper understanding of their impact on individuals, communities, and society in order to guide progress in the field. In this blog post, we highlight four research directions we believe to be critical to helping us more effectively map and mitigate the impacts of anthropomorphic AI, including providing more conceptual clarity about the ways in which AI system behaviors might be anthropomorphic; developing more precise terminology to describe these systems, their use, and their characteristics; developing and examining the effectiveness of possible interventions; and interrogating assumptions and practices that produce anthropomorphic AI systems.</p> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> </div> <d-bibliography src="/2025/assets/bibliography/2025-04-28-anthropomorphic-ai.bib"></d-bibliography> <d-article id="bibtex-container" class="related highlight"> For attribution in academic contexts, please cite this work as <pre id="bibtex-academic-attribution">
        PLACEHOLDER FOR ACADEMIC ATTRIBUTION
  </pre> BibTeX citation <pre id="bibtex-box">
        PLACEHOLDER FOR BIBTEX
  </pre> </d-article> <script src="https://utteranc.es/client.js" repo="iclr-blogposts/2025" issue-term="pathname" theme="github-light" crossorigin="anonymous" async> </script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> </body> </html>