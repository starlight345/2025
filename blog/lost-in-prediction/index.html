<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <script>let thunk=()=>{let e=e=>e.trim(),t=e=>e.innerText,n=e=>{let t=e.split(" "),n=t.slice(0,-1).join(" ");return[t.at(-1),n]},a=Array.from(document.getElementsByClassName("author")).map(t).map(e).map(n),o=a[0][0],i=(Array.from(document.getElementsByClassName("affiliation")).filter(e=>"P"===e.nodeName).map(t).map(e),"April 28, 2025"),r="Lost in Prediction: Why Social Media Narratives Don't Help Macroeconomic Forecasting?",l="Can we predict the macroeconomy by analyzing the narratives people share on social media? We dove deep into the world of Narrative Economics, using NLP models to analyze millions of viral tweets and see if they could help us predict the fluctuations of macroeconomic indicators. \ud83d\udea8 Spoiler alert: it's not that easy!  Join us as we explore the interesting relationship between narratives, social media, and macroeconomy, and uncover the challenges of turning narratives into treasure.";{let e=a.map(e=>`${e[0]}, ${e[1]}`).join(" and "),t=`\n@inproceedings{${(o+"2025"+r.split(" ").slice(0,3).join("")).replace(" ","").replace(/[\p{P}$+<=>^`|~]/gu,"").toLowerCase().trim()},\n  author = {${e}},\n  title = {${r}},\n  abstract = {${l}},\n  booktitle = {ICLR Blogposts 2025},\n  year = {2025},\n  date = {${i}},\n  note = {${window.location.href}},\n  url  = {${window.location.href}}\n}\n  `.trim();document.getElementById("bibtex-box").innerText=t}{let e=a.map(e=>e[0]),t=`\n${e=e.length>2?e[0]+", et al.":2==e.length?e[0]+" & "+e[1]:e[0]}, "${r}", ICLR Blogposts, 2025.\n`.trim();document.getElementById("bibtex-academic-attribution").innerText=t}};document.addEventListener("readystatechange",function(){"complete"===document.readyState&&thunk()});</script> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Lost in Prediction: Why Social Media Narratives Don't Help Macroeconomic Forecasting? | ICLR Blogposts 2025</title> <meta name="author" content="ICLR Blog"> <meta name="description" content="Can we predict the macroeconomy by analyzing the narratives people share on social media? We dove deep into the world of Narrative Economics, using NLP models to analyze millions of viral tweets and see if they could help us predict the fluctuations of macroeconomic indicators. üö® Spoiler alert: it's not that easy! Join us as we explore the interesting relationship between narratives, social media, and macroeconomy, and uncover the challenges of turning narratives into treasure."> <meta name="keywords" content="machine-learning, ml, deep-learning, reinforcement-learning, iclr"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/2025/assets/img/iclr_favicon.ico"> <link rel="stylesheet" href="/2025/assets/css/main.css"> <link rel="canonical" href="https://starlight345.github.io/2025/blog/lost-in-prediction/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/2025/assets/js/theme.js"></script> <script src="/2025/assets/js/dark_mode.js"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src="/2025/assets/js/distillpub/template.v2.js"></script> <script src="/2025/assets/js/distillpub/transforms.v2.js"></script> <script src="/2025/assets/js/distillpub/overrides.js"></script> <style type="text/css">.fake-img{background:#bbb;border:1px solid rgba(0,0,0,0.1);box-shadow:0 0 4px rgba(0,0,0,0.1);margin-bottom:12px}.fake-img p{font-family:monospace;color:white;text-align:left;margin:12px 0;text-align:center;font-size:16px}d-article h1{color:#0078d7!important;font-weight:bold;border-bottom:3px solid #0078d7!important}d-article h2{font-weight:400}.highlight{background-color:rgba(219,164,0,0.3);font-weight:bold}</style> <d-front-matter> <script async type="text/json">{
      "title": "Lost in Prediction: Why Social Media Narratives Don't Help Macroeconomic Forecasting?",
      "description": "Can we predict the macroeconomy by analyzing the narratives people share on social media? We dove deep into the world of Narrative Economics, using NLP models to analyze millions of viral tweets and see if they could help us predict the fluctuations of macroeconomic indicators. üö® Spoiler alert: it's not that easy!  Join us as we explore the interesting relationship between narratives, social media, and macroeconomy, and uncover the challenges of turning narratives into treasure.",
      "published": "April 28, 2025",
      "authors": [
        {
          "author": "Almog Gueta",
          "authorURL": "",
          "affiliations": [
            {
              "name": "Technion - IIT",
              "url": ""
            }
          ]
        },
        {
          "author": "Amir Feder",
          "authorURL": "https://www.amirfeder.com",
          "affiliations": [
            {
              "name": "Columbia University",
              "url": ""
            }
          ]
        },
        {
          "author": "Zorik Gekhman",
          "authorURL": "",
          "affiliations": [
            {
              "name": "Technion - IIT",
              "url": ""
            }
          ]
        },
        {
          "author": "Ariel Goldstein",
          "authorURL": "https://www.deepcognitionlab.com/",
          "affiliations": [
            {
              "name": "Hebrew University",
              "url": ""
            }
          ]
        },
        {
          "author": "Roi Reichart",
          "authorURL": "https://roireichart.com/",
          "affiliations": [
            {
              "name": "Technion - IIT",
              "url": ""
            }
          ]
        }
        
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script> </d-front-matter> </head> <body class="fixed-top-nav"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/2025/">ICLR Blogposts 2025</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/2025/about/">about</a> </li> <li class="nav-item "> <a class="nav-link" href="/2025/call/">call for blogposts</a> </li> <li class="nav-item "> <a class="nav-link" href="/2025/submitting/">submitting</a> </li> <li class="nav-item "> <a class="nav-link" href="/2025/reviewing/">reviewing</a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">past iterations</a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item" href="https://iclr-blogposts.github.io/2025/" rel="external nofollow noopener noopener noreferrer" target="_blank"><strong>2025</strong></a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="https://iclr-blogposts.github.io/2024/" rel="external nofollow noopener noopener noreferrer" target="_blank">2024</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="https://iclr-blogposts.github.io/2023/" rel="external nofollow noopener noopener noreferrer" target="_blank">2023</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="https://iclr-blog-track.github.io/home/" rel="external nofollow noopener noopener noreferrer" target="_blank">2022</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="post distill"> <d-title> <h1>Lost in Prediction: Why Social Media Narratives Don't Help Macroeconomic Forecasting?</h1> <p>Can we predict the macroeconomy by analyzing the narratives people share on social media? We dove deep into the world of Narrative Economics, using NLP models to analyze millions of viral tweets and see if they could help us predict the fluctuations of macroeconomic indicators. üö® Spoiler alert: it's not that easy! Join us as we explore the interesting relationship between narratives, social media, and macroeconomy, and uncover the challenges of turning narratives into treasure.</p> </d-title> <d-byline></d-byline> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div><a href="#what-is-narrative-economics">What is Narrative Economics?</a></div> <div><a href="#narrative-economics-at-the-macro-level">Narrative Economics at the Macro Level</a></div> <div><a href="#connecting-the-dots-testing-the-effectiveness-of-narratives-for-macroeconomic-forecasting">Connecting the Dots: Testing the Effectiveness of Narratives for Macroeconomic Forecasting</a></div> <div><a href="#what-can-we-take-away">What Can We Take Away?</a></div> <div><a href="#our-research-limits-and-challenges">Our Research Limits and Challenges</a></div> </nav> </d-contents> <script>if(window.innerWidth>768){var toc=document.getElementsByTagName("d-contents")[0];toc.style.position="fixed",toc.style.transition="transform 0.3s ease-out";var y0=toc.getBoundingClientRect().top+window.scrollY;window.addEventListener("scroll",function(){toc.style.transform=`translateY(${Math.max(0,window.scrollY-y0+180)}px)`})}</script> <h1 id="what-is-narrative-economics">What is Narrative Economics?</h1> <p>Narrative Economics is the study of how popular stories and ideas (a.k.a <strong>narratives</strong>) formed about the state of the economy could have real effects in the world. In this context, a ‚Äúnarrative‚Äù is a belief about the state of the world that is shared by the population, regardless of the actual state of the economy. For example, a narrative might be the belief that housing prices are increasing, whereas in reality (according to economic indicators) they are stagnating.</p> <p>The central idea is that the spread of viral narratives can influence individual and collective economic behavior, leading to fluctuations in markets, changes in investment patterns, and even broader economic shifts.</p> <div style="width: 70%; margin: 0 auto;"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/2025/assets/img/2025-04-28-lost-in-prediction/narrative_economics-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/2025/assets/img/2025-04-28-lost-in-prediction/narrative_economics-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/2025/assets/img/2025-04-28-lost-in-prediction/narrative_economics-1400.webp"></source> <img src="/2025/assets/img/2025-04-28-lost-in-prediction/narrative_economics.png" class="img-fluid z-depth-2" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p><br> The term ‚ÄúNarrative Economics‚Äù is heavily attributed to Robert J. Shiller, a Nobel laureate economist and the founder of the field, who defined it as:</p> <blockquote> <p><em>‚ÄúSpread through the public in the form of popular stories, <strong>ideas can go viral and move markets</strong> ‚Äîwhether it‚Äôs the belief that tech stocks can only go up, that housing prices never fall, or that some firms are too big to fail. Whether true or false, stories like these‚Äîtransmitted by word of mouth, by the news media, and increasingly by social media‚Äî<strong>drive the economy by driving our decisions about how and where to invest, how much to spend and save, and more.‚Äù</strong></em><br> <em>- Robert J. Shiller</em> <d-cite key="shiller2017narrative"></d-cite></p> </blockquote> <h2 id="the-ambiguity-of-the-term-narrative">The Ambiguity of the Term ‚ÄúNarrative‚Äù</h2> <p>The term ‚Äúnarrative‚Äù itself has different connotations in NLP compared to economics, which might lead to some confusion. üòµ‚Äçüí´</p> <p><strong>In NLP</strong>, narrative commonly refers to the structure and elements of stories, encompassing aspects like plot, characters, setting, and theme. It involves understanding how these elements interrelate and contribute to the overall meaning and coherence of a narrative.</p> <p><strong>In Narrative Economics</strong>, as stated in the above section, narrative is a shared belief or idea that spreads through the population and potentially influences economic behavior.</p> <p><strong>Our research uses the term ‚Äúnarrative‚Äù in the economic sense.</strong> We‚Äôre interested in how shared beliefs about the economy can be used to predict market trends.</p> <h3 id="but-how-can-we-capture-such-narratives">But, how can we capture such narratives?</h3> <p>The economic term is wide and it is undefined what requirements a story or idea must have in order to be considered as ‚Äúnarrative‚Äù. Yet, we can look at some characteristics Shiller mentions <d-cite key="coursera_narratives"></d-cite> about narratives to have a better understanding:</p> <ul> <li>First, the story should be viral, publicly believed, in order to change a large enough audience to move the market.</li> <li>Second, Shiller uses some propositions while explaining the term. He states that ‚Äúthe economic impact of narratives may change through time‚Äù and ‚Äúnarrative constellations have more impact than any one narrative‚Äù.</li> <li>Last, Shiller mentions social media as a source of narratives and Google Ngram as a tool for tracking them.</li> </ul> <p>Combined together, to capture a narrative, one would need a good measure of what many people are discussing, over time. Twitter (X), in this case, is an almost ideal source of information for capturing this distribution of opinions.</p> <h3 id="and-how-to-extract-the-narrative-aspect-from-tweets">And how to extract the ‚Äúnarrative‚Äù aspect from tweets?</h3> <p>Aligning with Shiller‚Äôs arguments and with existing literature, the extraction might be (for example) a sentiment <d-cite key="macaulay2023narrative, yang2023multi, adams2023more, kim2023forecasting, gurgul2023forecasting, wang2023deepemotionnet"></d-cite>, a topic <d-cite key="ash2021relatio"></d-cite>, or a specific economic outlook <d-cite key="nyman2021news, ahrens2021extracting, handlan2020text"></d-cite>.</p> <h2 id="social-media-narratives-ùïè">Social Media Narratives ùïè</h2> <p>We have collected<d-footnote>Data is available through the Social Media Archive (SOMAR): "https://socialmediaarchive.org/record/77".</d-footnote> two comprehensive datasets of tweets from Twitter (X), a platform chosen for its real-time reflection of public opinions and ability to capture diverse economic narratives. These datasets cover a broad time-frame, and a wide range of topics relevant to the economy, including economics, business, politics, and current events, ensuring a broad and comprehensive representation of narratives.</p> <p>Both datasets were carefully curated using targeted queries with the inclusion of specific keywords, and were analyzed to ensure quality and relevant for capturing economic narratives.</p> <p><strong>Pre-Pandemic Twitter Dataset:</strong> Utilizing Twitter API <d-cite key="Twitter-API"></d-cite>, we collected 2.4 million tweets from Twitter‚Äôs early days (January 2007) to COVID-19 pandemic (December 2020). To prioritize viral tweets, we retrieved the daily top 200 tweets based on follower count, then we randomly sampled 100 to mitigate potential bias towards highly active accounts typically associated with news outlets. This process yielded a dataset contributed by about 250,000 users per collected topic, each boasting an average follower count of 100 million, including global leaders, news outlets and other influencers.</p> <p><strong>Post-2021 Twitter Dataset:</strong> We wanted to test the predictive power of our employed LLM (OpenAI‚Äôs Chat Completion API with GPT-3.5 <d-cite key="ChatGPT-3.5"></d-cite>) on a timeframe beyond the LLM‚Äôs data cutoff date (September 2021). Therefore, we collected a second dataset ranging from September 2021 until July 2023. This assures the LLM relies solely on provided tweets and pre-existing knowledge, unaware of ‚Äòfuture‚Äô knowledge. Here we collected the tweets monthly, using Twitter Advanced Search, restricting the search to users with at least 1,000 followers. Overall we curated 2,881 tweets <d-footnote>As this data collection method is more restricted than the previous, the resulting dataset is relatively smaller.</d-footnote>, contributed by 1,255 users, including politicians, CEOs, activists, and academics.</p> <p>An example tweet can be:</p> <div style="display: flex; justify-content: center;"> <div class="jekyll-twitter-plugin"> <blockquote class="twitter-tweet"> <p lang="en" dir="ltr">This is so silly. The deficit is decreasing because we‚Äôre not doing pandemic aid anymore, and federal receipts are up because of inflation. Congress, or the Biden administration, didn‚Äôt do anything to lower the deficit. <a href="https://t.co/kvlLPpsUO9" rel="external nofollow noopener noopener noreferrer" target="_blank">https://t.co/kvlLPpsUO9</a></p>‚Äî New Liberals üåêüá∫üá¶ (@CNLiberalism) <a href="https://twitter.com/CNLiberalism/status/1525672295775223808?ref_src=twsrc%5Etfw" rel="external nofollow noopener noopener noreferrer" target="_blank">May 15, 2022</a> </blockquote> <script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> </div> </div> <p>This tweet from influential user @CNLiberalism exemplifies the economic narratives captured in our dataset. Posted in May 2022, it captures real-time public concerns about inflation and its impact on the deficit. This type of narrative can influence consumer behavior and market trends, which is central to our research.</p> <h3 id="does-our-dataset-contain-narratives">Does Our Dataset Contain Narratives?</h3> <p>To confirm the presence of narratives within our Twitter dataset, we conducted an analysis using RELATIO <d-cite key="ash2021relatio"></d-cite>, a tool designed to ‚Äúcapture political and economic narratives‚Äù by mapping relationships and interactions among entities within a corpus. Upon processing our dataset with RELATIO, we obtained ‚Äúnarrative statements‚Äù (as defined in their paper) and visualized their temporal distribution:</p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/2025/assets/img/2025-04-28-lost-in-prediction/relatio_plot-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/2025/assets/img/2025-04-28-lost-in-prediction/relatio_plot-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/2025/assets/img/2025-04-28-lost-in-prediction/relatio_plot-1400.webp"></source> <img src="/2025/assets/img/2025-04-28-lost-in-prediction/relatio_plot.png" class="img-fluid z-depth-2" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <p>We can see the evolving nature of these narratives over time, where the distribution is aligned with real-life related events. üëç</p> <h3 id="llms-show-potential-in-understanding-narratives">LLMs Show Potential in Understanding Narratives</h3> <p>A more advanced technique to extract and analyze narratives is using LLMs. Prompting OpenAI‚Äôs Chat Completion API, GPT-3.5 <d-cite key="ChatGPT-3.5"></d-cite> with monthly tweets and prices of economic indicator from matching dates, we generated<d-footnote>Data is available through the Social Media Archive (SOMAR): "https://socialmediaarchive.org/record/77".</d-footnote> LLM-based narratives analysis, one for each date in the post-2021 dataset, containing a component of summarized analysis of the tweets and a component of potential effect on the given financial indicator.</p> <p>Here‚Äôs a snippet of such an LLM-based narrative analysis for inputs of dates 29/08/2022 to 28/09/2022. In this time period, the Federal Reserve raised interest rates in an effort to combat inflation and the US Supreme Court ruled that the Biden administration could not extend the pause on student loan payments:</p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/2025/assets/img/2025-04-28-lost-in-prediction/chatgpt_snippet-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/2025/assets/img/2025-04-28-lost-in-prediction/chatgpt_snippet-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/2025/assets/img/2025-04-28-lost-in-prediction/chatgpt_snippet-1400.webp"></source> <img src="/2025/assets/img/2025-04-28-lost-in-prediction/chatgpt_snippet.jpg" class="img-fluid z-depth-2" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <p>This snippet demonstrates the LLM‚Äôs ability to aggregate information, condensing and distinguishing between opinions and occurrences conveyed in the tweets. Moreover, the LLM links its insights to potential future consequences for the financial indicator, a pivotal initial move towards prediction. üëç</p> <hr> <h1 id="narrative-economics-at-the-macro-level">Narrative Economics at the Macro Level</h1> <p>Now that we are familiar with Narrative Economics and have established how we gathered these narratives from Twitter, let‚Äôs explore why we chose to focus on <em>macroeconomics</em>:</p> <p><strong>Macro</strong>ceconomics studies the behavior of the economy as a whole, examining factors like inflation, unemployment, and economic growth. <strong>Micro</strong>economics, on the other hand, is concerned with the decision-making of individuals and firms, examining indicators like a certain stock.</p> <h3 id="why-macroeconomics">Why Macroeconomics?</h3> <p>A core concept in Narrative Economics is that narratives can drive economics fluctuations. This is especially intriguing at the macroeconomic level, as the theory suggests that widely shared stories can influence the collective decisions of millions of individuals. Additionally, existing research focuses on microeconomic indicators within the context of Narrative Economics <d-cite key="yang2023multi, khedr2021cryptocurrency, he2021multi, gurgul2023forecasting, wang2023deepemotionnet"></d-cite>, while the application in macroeconomics remains relatively unexplored.</p> <p>However, studying this at the macroeconomic level is more complex than at the microeconomic level due to the complex interplay of various factors, the need for broadly covering narratives, and the inherent difficulty in isolating causal relationships.</p> <h3 id="our-macroeconomic-indicators">Our Macroeconomic Indicators</h3> <p>We focus on predicting three key macroeconomic indicators:</p> <p><strong>Federal Funds Rate (FFR):</strong> The interest rate at which depository institutions, such as banks, lend reserve balances overnight to meet reserve requirements. The FFR serves as a Federal Reserve monetary policy tool, is influenced by public perception of economic stability, and its fluctuations impact various sectors, making it widely monitored.</p> <p><strong>S&amp;P 500:</strong> A stock market index measuring the performance of the 500 largest publicly traded companies in the U.S. It reflects collective investor confidence in economic growth and risk appetite and is widely regarded as a barometer of the overall health of the US stock market.</p> <p><strong>CBOE Volatility Index (VIX):</strong> Measures market expectations of future volatility based on S&amp;P 500 options prices, often referred to as the ‚Äòfear gauge‚Äô as it tends to rise during market stress and fall during market stability.</p> <p>These indicators are well-suited for testing the predictive power of narratives in macroeconomics due to their daily frequency, which aligns with the rapid pace of Twitter, and their sensitivity to public sentiment and behavior.</p> <hr> <h1 id="connecting-the-dots-testing-the-effectiveness-of-narratives-for-macroeconomic-forecasting">Connecting the Dots: Testing the Effectiveness of Narratives for Macroeconomic Forecasting</h1> <p>The previous two sections discussed the theory of Narrative Economics and our curated Twitter dataset, which holds narratives within them, and the distinction between macroeconomics and microeconomics, explaining why it is interesting to research the theory at the macroeconomic level and which macroeconomic indicators we chose.</p> <p>We can now delve into the series of experiments we tested to assess the central question - <strong>can economic narratives provide valuable insights for future macroeconomic movements?</strong></p> <p>Each experiment tests the predictive power of narratives from the curated datasets, for macroeconomic prediction of one (or more) of the financial targets introduced before: FFR, S&amp;P 500, and VIX.</p> <p>We won‚Äôt be able to cover all the details of the experiments in this blog, but it is available in our paper <d-cite key="gueta2024can"></d-cite>.</p> <h2 id="experimental-setup">Experimental Setup</h2> <h3 id="prediction-tasks">Prediction Tasks</h3> <p>We test the predictive power of narratives on three tasks commonly used in macroeconomic literature <d-cite key="handlan2020text, 10.1257/jel.20181020, kalamara2022making, ahrens2021extracting, masciandaro2021monetary, lee2009federal, hamilton2002model, kim2023forecasting, larkin2008good"></d-cite>:</p> <ul> <li> <strong>Next value:</strong> Predicts the target‚Äôs value at the specified horizon.</li> <li> <strong>Percentage change:</strong> Predicts the target‚Äôs percentage change between the specified horizon and the day before.</li> <li> <strong>Direction change:</strong> Classifies the target‚Äôs direction of change (increase or decrease) between the specified horizon and the day before.</li> </ul> <h3 id="models-categories">Models Categories</h3> <p>We divide our models into 3 categories based on their input signal:</p> <ul> <li> <strong>Financial (F):</strong> Utilizes historical financial data, from the past week or month.</li> <li> <strong>Textual (T):</strong> Leverages solely textual data, either raw tweets or tweets‚Äô analyses.</li> <li> <strong>Textual &amp; Financial (TF):</strong> Draws upon both textual and financial data as input.</li> </ul> <p>Our goal is to effectively leverage insights from both textual narratives and historical financial patterns to improve prediction accuracy. The added value of incorporating textual narratives can be demonstrated if a model that utilizes both text and financial data (TF model) outperforms a model that relies solely on financial data (F model).</p> <h3 id="baselines">Baselines</h3> <p><strong>Financial baselines:</strong></p> <ul> <li> <strong>As/Inverse-previous:</strong> Next value is the same/inverse as previous.</li> <li> <strong>Majority:</strong> Next value is the majority vote of the previous week/training data.</li> <li> <strong>Up/Down:</strong> Always predict ‚Äòincrease‚Äô/‚Äôdecrease‚Äô.</li> </ul> <p><br></p> <p><strong>Counterfactual textual baselines:</strong></p> <p>During our experiments, we encountered some intriguing results that warranted further investigation. To ensure the validity of our findings and rule out any counterfactual explanations, we introduced counterfactual textual baselines. These baselines allowed us to rigorously test whether the observed improvements were truly due to the models‚Äô capabilities or stemmed from other factors. Unfortunately, these baselines revealed that the promising results were more elusive than we hoped.</p> <ul> <li> <strong>Random texts:</strong> Feeding the LLM with randomly generated sentences comprised of varying random words. This baseline evaluates whether the LLM actually utilizes the content of tweets.</li> <li> <strong>Shuffled tweets:</strong> Feeding the LLM with chronologically disordered tweets, isolating the impact of temporal narratives from confounding patterns or memorization. This baseline assesses the model reliance on temporal narratives.</li> <li> <strong>Synthetic ‚Äònarratives‚Äô:</strong> Feeding the LLM with generated narrative-like sentences expressing positive or negative cues, aligned with subsequent changes in the financial target. This baseline assesses the LLM‚Äôs ability to infer relationships between aligned narratives and the following market changes.</li> </ul> <h3 id="models">Models</h3> <p>Our model selection progresses from simpler models, frequently employed in the financial literature <d-cite key="arthur1995complexity, andersen1999forecasting, 10.1257/0895330041371321, hamilton2002model, athey2019machine, kalamara2022making, 10.1257/jel.20181020, masciandaro2021monetary"></d-cite>, to more advanced architectures. This progression serves two purposes:</p> <ol> <li>Achieving positive results with simpler models provides a stronger evidence for the predictive signal of narratives.</li> <li>It allows us to build upon existing research in Narrative Economics, which is primarily rooted in finance and often utilizes relatively simple models, before exploring more advanced NLP approaches.</li> </ol> <p><br></p> <p><strong>Financial models:</strong> These include traditional ML models (e.g., Linear Regression, SVM), DA-RNN <d-cite key="qin2017dual"></d-cite>, and T5 <d-cite key="raffel2020exploring"></d-cite> which receives financial data input in a text format. Each model is fed with a sequence of historical financial values of the target indicator, either as individual features per day or as a time-series.</p> <p><br></p> <p><strong>Textual models:</strong></p> <ul> <li> <strong>Daily sentiment:</strong> A simple method, commonly used in the literature, is presenting each tweet with its sentiment score. Then, we average the scores of individual tweets of the same dates to receive a daily sentiment, and concatenate over a week.</li> </ul> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/2025/assets/img/2025-04-28-lost-in-prediction/models_diagram_1-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/2025/assets/img/2025-04-28-lost-in-prediction/models_diagram_1-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/2025/assets/img/2025-04-28-lost-in-prediction/models_diagram_1-1400.webp"></source> <img src="/2025/assets/img/2025-04-28-lost-in-prediction/models_diagram_1.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <ul> <li> <strong>LLM‚Äôs representations of individual/joint tweets:</strong> We derive embeddings of individual or concatenated tweets using pre-trained language models (BERT <d-cite key="devlin2018bert"></d-cite>, RoBERTa <d-cite key="liu2019roberta"></d-cite>, and T5 <d-cite key="raffel2020exploring"></d-cite>). In the individual case, tweet embeddings are aggregated daily by averaging or concatenating embeddings of same-date tweets. In the joint case, tweets are concatenated daily to create a single daily embedding, potentially capturing their collective meaning without explicit aggregation, avoiding potential information loss.</li> </ul> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/2025/assets/img/2025-04-28-lost-in-prediction/models_diagram_2-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/2025/assets/img/2025-04-28-lost-in-prediction/models_diagram_2-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/2025/assets/img/2025-04-28-lost-in-prediction/models_diagram_2-1400.webp"></source> <img src="/2025/assets/img/2025-04-28-lost-in-prediction/models_diagram_2.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <ul> <li> <strong>LLM-generated analyses for prediction or as input to a subsequent prediction model:</strong> First, we feed OpenAI‚Äôs Chat Completion API, GPT-3.5 <d-cite key="ChatGPT-3.5"></d-cite> with a month of tweets and corresponding financial values of the target indicator to create monthly analyses.Then, these analyses are either used directly for prediction or as an input to a subsequent T5 model.<br> *since the LLM receives both tweets and financial data to enable analyzing relationships, this method applies only for a TF model type.</li> </ul> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/2025/assets/img/2025-04-28-lost-in-prediction/models_diagram_3-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/2025/assets/img/2025-04-28-lost-in-prediction/models_diagram_3-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/2025/assets/img/2025-04-28-lost-in-prediction/models_diagram_3-1400.webp"></source> <img src="/2025/assets/img/2025-04-28-lost-in-prediction/models_diagram_3.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <p><br></p> <p><strong>Fusing textual and financial models:</strong> We experiment with several strategies for combining the representations from the T and F models for unified prediction:</p> <ul> <li> <strong>Concatenation:</strong> The simplest approach is concatenating the T and F representations.</li> <li> <strong>DA-RNN <d-cite key="qin2017dual"></d-cite>:</strong> The dual-stage attention-based RNN model predicts the current value of a time-series based on its previous values and those of exogenous series. We feed historical financial representations (F) as the time series and textual representations (T) as the exogenous series.</li> <li> <p><strong>Prompt-based fusion:</strong> LLM-based analysis of given tweets and historical financial values of the target indicator are fed together with raw historical values of the target to a T5 model as separate segments.</p> <p>Given a TF model, we can derive a T or F model by omitting or zeroing either F or T component, respectively.</p> </li> </ul> <h2 id="the-challenges-in-improving-models-with-narratives">The Challenges in Improving Models with Narratives</h2> <p><strong>TL;DR:</strong></p> <ul> <li>Models incorporating narratives (TF) show limited improvement over those using solely financial data (F).</li> <li>Gains were inconsistent, marginal and statistically insignificant. We regard it as negative results.</li> </ul> <h3 id="sentiment-based-prediction">Sentiment-Based Prediction</h3> <p>We fed classic ML models with daily sentiments for FFR ‚Äònext value‚Äô and ‚Äòdirection change‚Äô prediction (as separate tasks).</p> <p><strong>The results:</strong></p> <ul> <li>Direction change: üí° <span class="highlight">Adding sentiment data didn‚Äôt help</span>, as both models with financial input (F &amp; TF) achieved similar accuracy (0.939 vs. 0.936). Additionally, text-only models (T) underperformed (0.89), achieving a comparable accuracy to the F baselines (0.89 vs. 0.81).</li> </ul> <table> <thead> <tr> <th>Type</th> <th>Model</th> <th>Accuracy</th> </tr> </thead> <tbody> <tr> <td>F baseline</td> <td>As-previous</td> <td>0.812</td> </tr> <tr> <td>F</td> <td>Random Forest Numeric</td> <td><strong>0.936</strong></td> </tr> <tr> <td>TF</td> <td>Random Forest Numeric</td> <td><strong>0.939</strong></td> </tr> <tr> <td>T</td> <td>Logistic Regression</td> <td>0.885</td> </tr> </tbody> <tbody> <tr> <td>¬†</td> <td>SVM</td> <td>0.885</td> </tr> </tbody> </table> <p><br></p> <ul> <li>Next value: üí° <span class="highlight">None of the models, with or without sentiment or financial data, outperformed the non-learned ‚Äòtrain-mean‚Äô baseline</span> (15.4, 15.6).</li> </ul> <table> <thead> <tr> <th><strong>Type</strong></th> <th><strong>Model</strong></th> <th><strong>MSE</strong></th> </tr> </thead> <tbody> <tr> <td>F baseline</td> <td>Train-mean</td> <td>15.661</td> </tr> <tr> <td>F</td> <td>SVM</td> <td>15.416</td> </tr> <tr> <td>TF</td> <td>SVM</td> <td>15.416</td> </tr> <tr> <td>T</td> <td>SVM</td> <td>15.36</td> </tr> </tbody> </table> <p><br></p> <p><strong>What can we learn? ü§î</strong> Sentiment analysis lacks the nuance necessary for accurate financial prediction, and traditional ML models have limitations in capturing complex market dynamics. ‚û°Ô∏è We need an improved text representations and more advanced prediction models.</p> <h3 id="embeddings-for-time-series-prediction">Embeddings for Time-Series Prediction</h3> <p>Here we turn to embedding-representations (as explained in the Experimental Setup) and to DA-RNN <d-cite key="qin2017dual"></d-cite> model, which is designed to capture temporal dynamics and complex relationships within its given data.</p> <p>We extensively evaluated various model configurations, target indicators (FFR and VIX), tasks (‚Äònext value‚Äô, ‚Äòpercentage change‚Äô, ‚Äòdirection change‚Äô and the last two together), prediction horizons (next-day, next-week), LLM architectures (see Experimental Setup), aggregation methods, and the daily number of tweets given as input. Additionally, we assessed the models‚Äô reliance on temporal context and relevant narratives using the counterfactual textual baselines.</p> <p>To keep it short, we present results only for predicting the VIX ‚Äònext value‚Äô of the next-day and next-week (as separate tasks). Additional experiments showed a recurring pattern to the presented results.</p> <p><strong>The results:</strong></p> <div style="width: 70%; margin: 0 auto;"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/2025/assets/img/2025-04-28-lost-in-prediction/embeddings_exp_results-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/2025/assets/img/2025-04-28-lost-in-prediction/embeddings_exp_results-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/2025/assets/img/2025-04-28-lost-in-prediction/embeddings_exp_results-1400.webp"></source> <img src="/2025/assets/img/2025-04-28-lost-in-prediction/embeddings_exp_results.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li> <p>Next-day prediction: üí° <span class="highlight">The non-learned ‚Äòas-previous‚Äô F baseline outperforms all other models</span> (3.079 MSE). This suggests that the input data may not be beneficial for such a short-term prediction.</p> </li> <li> <p>Next-week prediction: <span class="highlight">Initially both TF models (13.148, 13.147) appeared to outperform the F model (13.463) and F baseline</span> (16.172), implying a potential influence of the textual content. <br> üí° <span class="highlight">However, the ‚Äòrandom texts‚Äô TF baseline</span> (13.056), which replaced actual tweets with randomly generated text, <span class="highlight">outperformed all other models</span>, indicating the observed improvement was not driven by meaningful textual content.</p> </li> </ul> <p>We hypothesize that the presence of text improves performance, even when random, due to spurious correlations or random noise aiding generalization, similar to regularization techniques. A contributing factor may be the difficulty of effectively capturing and representing aggregated tweet information for financial prediction, as well as the inherent challenges in predicting future values of a volatile financial indicator, characterized by frequent random movements and fluctuations, using its historical values. ¬†</p> <p><strong>What can we learn? ü§î</strong> Our models struggled to leverage tweets for the prediction, indicating that implicitly capturing and aggregating latent narratives within LLMs remains a challenge.</p> <h3 id="predicting-using-llm-analyses">Predicting Using LLM Analyses</h3> <p><strong>Can LLMs generate an accurate prediction?</strong> We first tried to directly predict the financial indicator (average weekly VIX or S&amp;P 500) as a generative response of the web chat version of GPT <d-cite key="gpt-chat"></d-cite> prompted with a monthly window of tweets and corresponding values of the financial target. This resulted in limited inconsistent success. üí° <span class="highlight">While the LLM consistently generated insightful narrative analyses and demonstrated comprehension of financial implications, it exhibited inconsistencies when applying these insights for prediction.</span> For instance, it occasionally refused to provide predictions, or it would simply mirror input ranges, neglecting the potential impact of the narratives it successfully analyzed. When presented with ‚Äòsynthetic narratives‚Äô, it recognized the change direction but struggled to quantify the magnitude of it.</p> <p><br></p> <p><strong>Repurposing the LLM analyses for a subsequent prediction model:</strong> The previous experiment revealed the LLM‚Äôs ability to generate insightful analyses of tweets and financial data. To leverage this capability, we utilize these analyses as inputs for a dedicated prediction model to predict the S&amp;P 500 ‚Äòdirection change‚Äô.</p> <p>This approach addresses limitations of the two previous experiments by:</p> <ul> <li>Instead of relying on the embedding-based approach, which struggled to aggregate diverse narratives, we leverage the LLM‚Äôs ability to produce concise analyses. ¬†</li> <li>Instead of directly using the LLM for prediction, which exhibited inconsistencies, we utilize a separate fine-tuned model for downstream prediction.</li> </ul> <p><strong>The results:</strong></p> <table> <thead> <tr> <th>Type</th> <th>Model</th> <th>Accuracy</th> <th>F<sub>1</sub>-Score</th> </tr> </thead> <tbody> <tr> <td>¬†</td> <td>Train-majority</td> <td>0.424</td> <td>0.0</td> </tr> </tbody> <tbody> <tr> <td>¬†</td> <td>Week-majority</td> <td>0.484</td> <td>0.598</td> </tr> </tbody> <tbody> <tr> <td>F-baselines</td> <td>As-previous</td> <td>0.484</td> <td>0.552</td> </tr> </tbody> <tbody> <tr> <td>¬†</td> <td>Inverse-previous</td> <td>0.517</td> <td>0.511</td> </tr> </tbody> <tbody> <tr> <td>¬†</td> <td>Up-predictor</td> <td>0.576</td> <td>0.731</td> </tr> </tbody> <tbody> <tr> <td>¬†</td> <td>Down-predictor</td> <td>0.424</td> <td>0.0</td> </tr> <tr> <td>F</td> <td>T5 Base</td> <td><strong>0.604</strong></td> <td>0.723</td> </tr> </tbody> <tbody> <tr> <td>¬†</td> <td>T5 Large</td> <td>0.593</td> <td><strong>0.727</strong></td> </tr> <tr> <td>TF</td> <td>T5 Base</td> <td>0.626</td> <td>0.738</td> </tr> </tbody> <tbody> <tr> <td>¬†</td> <td>T5 Large</td> <td><strong>0.627</strong></td> <td><strong>0.742</strong></td> </tr> <tr> <td>T</td> <td>T5 Large</td> <td>0.587</td> <td>0.726</td> </tr> <tr> <td>T-baseline</td> <td>Synthetic narratives</td> <td>0.489</td> <td>0.254</td> </tr> </tbody> </table> <p><strong>Did it work?</strong> Unfortunately, not really. üí° Results show that <span class="highlight">there is no significant difference between the best TF and F models</span>, with a performance gap of ~2% on the limited test set of ~90 samples. <d-footnote>As a reminder, we can only use the second Twitter dataset, of tweets that were posted after the LLM's training cutoff date, and our financial indicators are of daily frequency, therefore the small dataset for this type of experiments.</d-footnote> We confirmed it using the McNemar‚Äôs test <d-cite key="P18-1128"></d-cite>, which showed no statistically significant difference (p-value=0.48). On the good side, this is the only approach where our models surpassed all baselines.</p> <p><strong>What can we learn? ü§î</strong> While LLMs can analyze narratives, the TF model struggled to effectively leverage this analysis for improved prediction.</p> <hr> <h1 id="what-can-we-take-away">What Can We Take Away?</h1> <p>Despite the presence of narratives in our curated datasets and the development of NLP tools for narrative extraction, evaluating their impact on macroeconomic prediction remains challenging. Our models incorporating narrative data showed limited improvement over those using only financial data, failing to consistently outperform baselines or financial models. Any observed improvements were marginal and statistically insignificant and we regard it as a negative result.</p> <p>The missing link between the successful narrative extraction demonstrated by the LLM‚Äôs analyses and the limited improvement in macroeconomic prediction <strong>raises a question about the extent to which narratives alone can truly drive and forecast economic fluctuations</strong>, at least at the macroeconomic level.</p> <p>This study serves as a foundation for further exploration, highlighting the need for new macroeconomic models or tasks that can effectively assess the influence of extracted narratives on the economy.</p> <hr> <h1 id="our-research-limits-and-challenges">Our Research Limits and Challenges</h1> <p>Like any research, this project has potential limitations and faced several interesting challenges:</p> <p>First, we focused on ‚Äúnowcasting‚Äù ‚Äì predicting indicators right now or very soon. Economic markets are inherently complex and involve randomness, making accurate short-term prediction a significant challenge. The Efficient Market Hypothesis suggests that the predictive power of nowcasting is limited as asset prices react instantly to public information. However, Narrative Economics theory proposes that narratives affect people‚Äôs decisions, potentially giving us an edge in predicting economic fluctuations <d-cite key="shiller2017narrative"></d-cite>.</p> <p>We only looked at a few specific economic variables (FFR, S&amp;P 500, and VIX), influenced and shifted by diverse, external, and unobserved sources. Looking at different targets, or trying other tasks like detecting market anomalies or predicting profit, might have shown stronger evidence of the impact of narratives on the economy.</p> <p>The challenge of timing: When does a narrative actually start to impact the market, and for how long? Does it take hours, days, weeks? Although comprehensive, our experiments only examined a limited set of time lags and prediction horizons.</p> <p>What IS a Narrative?: While our datasets were carefully curated to capture potential narratives, definitively identifying them is challenging, especially when trying to aggregate multiple narratives for a holistic economic picture. The definition of ‚Äúnarrative‚Äù itself is broad and subjective, often only becoming clear in retrospect. This, combined with the inherent noise, biases, and misinformation common on social media, makes extracting clear, reliable narratives a complex task.</p> <p>Our worldview: Our analysis relies on English-language data from Twitter and focused on US-centric macroeconomic indicators. Narratives and economies work differently around the world and on different social media platforms or other outlets. This is definitely an area for future expansion.</p> <p>Lastly, we are limited to publicly accessible LLMs with a known cutoff date to ensure the models couldn‚Äôt ‚Äúcheat‚Äù by accessing future knowledge. However, utilizing different models might lead to better results.</p> <p>A quick word on ethics: This research involves technology aimed at predicting human and economic behavior. It‚Äôs vital to state clearly that this kind of tech could be misused in harmful or unfair ways (e.g., for market manipulation or unfair practices). We strongly believe it needs to be developed and used with caution and constant awareness of its ethical implications.</p> <hr> <p><br></p> <p><em>This blogpost extends the technical experiments presented in our paper <d-cite key="gueta2024can"></d-cite>, delving deeper into broader aspects that naturally in a paper can only receive a shorter discussion as it primarily presents the technical results. We invite you to read the paper for comprehensive background and detailed experiments.</em></p> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> </div> <d-bibliography src="/2025/assets/bibliography/2025-04-28-lost-in-prediction.bib"></d-bibliography> <d-article id="bibtex-container" class="related highlight"> For attribution in academic contexts, please cite this work as <pre id="bibtex-academic-attribution">
        PLACEHOLDER FOR ACADEMIC ATTRIBUTION
  </pre> BibTeX citation <pre id="bibtex-box">
        PLACEHOLDER FOR BIBTEX
  </pre> </d-article> <script src="https://utteranc.es/client.js" repo="iclr-blogposts/2025" issue-term="pathname" theme="github-light" crossorigin="anonymous" async> </script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> </body> </html>